# V â€“ AI Coding Agent ðŸ¤–ðŸ’»

V is a teaching-first AI coding agent that demonstrates AI agent design patterns in practice.  
It is built on Google Geminiâ€™s function calling capabilities and shows how an LLM can plan, critique, and act through tools instead of just generating text.

---
Basic structure of "V":

+-------------------+
|      USER         |
| "Explain hello.py"|
+---------+---------+
          |
          v
+-------------------+
|        V          |
|   (AI Agent)      |
| - Receives prompt |
| - Prepares system |
|   instructions    |
+---------+---------+
          |
          v
+-------------------+
|  Gemini LLM       |
|  (Model)          |
| - Thinks about    |
|   what to do      |
| - Decides which   |
|   tool to call    |
+---------+---------+
          |
          v
+-------------------+      Tool Calls
|     Tool Layer    |----------------------------+
|  (Python funcs)  |                            |
| - get_files_info  |                            |
| - get_file_content|                            |
| - write_file      |                            |
| - run_python_file |                            |
+---------+---------+                            |
          |                                      |
          v                                      |
+-------------------+                            |
|  Tool Result       |<--------------------------+
| - File content     |
| - Directory list   |
| - Execution output |
+---------+---------+
          |
          v
+-------------------+
| Reflection Loop    |
| - LLM critiques   |
|   result          |
| - Decides if more |
|   steps needed    |
+---------+---------+
          |
          v
+-------------------+
|   Final Answer     |
| - Printed output   |
| - Optional verbose |
+-------------------+


## ðŸ§  AI Agent Design Patterns in V

V is not just a code runner â€” it follows modern agent design principles:

### ðŸ”§ Tool Use
The agent doesnâ€™t try to â€œhallucinateâ€ file contents or execution results. Instead, it calls specialized tools (Python functions you provide):

- `get_files_info` â€“ inspect project structure  
- `get_file_content` â€“ read code safely  
- `write_file` â€“ create or edit files  
- `run_python_file` â€“ execute Python scripts  

This makes V grounded and reliable, since it works with the real environment instead of guessing.

### ðŸªž Reflection Loop
Instead of answering once and stopping, V follows a multi-step loop (up to 20 iterations):

1. **Think** â€“ The LLM reasons internally about your request.  
2. **Act** â€“ It calls the right tool.  
3. **Observe** â€“ It inspects the tool result.  
4. **Reflect** â€“ It critiques whether the result is enough or needs another step.  
5. **Repeat** â€“ Until a final, high-quality answer is ready.  

This mimics how humans work on coding tasks: explore, test, revise, then explain.

---

## âœ¨ Features

- ðŸ“‚ List files and directories  
- ðŸ“– Read file content with safe truncation  
- âœï¸ Write or overwrite files  
- â–¶ï¸ Run Python files with arguments  
- ðŸ”„ Multi-step reasoning with Reflection Pattern  
- ðŸ› ï¸ Agentic Tool Use (real functions, not hallucinated code)  

---
AI Reflection:
This script simply prints 'Hello, World!' to the console when executed.
ðŸ“Œ Why This Matters
V shows how to go beyond a simple chatbot and implement agentic behavior:
Instead of spitting out code, the agent executes real actions.
Instead of answering once, it reflects and iterates until the task is done.
Instead of being rigid, it uses modular tools that can be extended (add your own!).
This makes it a mini framework for experimenting with AI agent design.
ðŸ“œ License
MIT License â€“ free to use, modify, and learn from.

## ðŸ› ï¸ Installation

Clone this repository:

```bash
git clone https://github.com/your-username/v-code-agent.git
cd v-code-agent
Set up environment:
python3 -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
pip install -r requirements.txt
Add your Gemini API key in .env:
GEMINI_API_KEY=your_api_key_here
ðŸš€ Usage
Run V with a natural request:
python main.py "Could you explain the code in hello.py?"
Verbose mode (shows token usage):
python main.py "Run the script in test.py with arg1=hello" --verbose
ðŸ“‚ Project Structure
.
â”œâ”€â”€ main.py                 # Core agent logic + reflection loop
â”œâ”€â”€ functions/
â”‚   â”œâ”€â”€ get_file_content.py # Tool: read files
â”‚   â”œâ”€â”€ get_files_info.py   # Tool: list directories
â”‚   â”œâ”€â”€ run_python_file.py  # Tool: execute code
â”‚   â””â”€â”€ write_file.py       # Tool: write files
â”œâ”€â”€ config.py               # Config (e.g. MAX_CHARS)
â”œâ”€â”€ .env                    # Gemini API key
â””â”€â”€ requirements.txt        # Dependencies
ðŸ§© Example Interaction
Prompt:
python main.py "Could you explain the code in hello.py?"
Output (simplified):
Function result (get_file_content):
print("Hello, World!")




---
